{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers with Keras: Translation\n",
    "https://keras.io/examples/nlp/neural_machine_translation_with_transformer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import keras\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1.keras import layers\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "\n",
    "\n",
    "# set GPU config\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement=True\n",
    "config.allow_soft_placement=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "\n",
    "\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)\n",
    "\n",
    "loss_scale = policy.loss_scale\n",
    "print('Loss scale: %s' % loss_scale)\n",
    "\n",
    "\n",
    "# default is 1e-7 which is too small for float16.  Without adjusting the epsilon, we will get NaN predictions because of divide by zero problems\n",
    "float_type = 'float16'\n",
    "print(\"keras backend float size before: \", K.floatx())\n",
    "K.set_epsilon(1e-4) \n",
    "K.set_floatx(float_type)\n",
    "\n",
    "# set the new configs\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G = len(tf.config.experimental.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available: \", G)\n",
    "print(\"tf version \", tf.__version__)\n",
    "print(\"keras version \", tf.keras.__version__)\n",
    "print(\"keras backend float size: \", K.floatx())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = np.load('data/x_train_SMALL.npy')\n",
    "y_train = np.load('data/y_train_SMALL.npy')\n",
    "\n",
    "x_val = x_train\n",
    "y_val = y_train\n",
    "\n",
    "\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_val), \"Validation sequences\")\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data shape\n",
    "NUM_FEATS = 60\n",
    "SEQ_LEN = 50\n",
    "vocab_size = 300 # number of discrete tokens\n",
    "maxlen = SEQ_LEN # Setting this to reflect sequence length\n",
    "\n",
    "\n",
    "## Model dimensions\n",
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 4  # Number of attention heads\n",
    "latent_dim = 256  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "\n",
    "## Training params\n",
    "\n",
    "patience = 5\n",
    "BS = 16*G\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(inp, targ):\n",
    "    return ({\"encoder_inputs\": inp, \"decoder_inputs\": targ,},targ)\n",
    "\n",
    "\n",
    "def make_dataset(x,y,bs):\n",
    "    x = list(x)\n",
    "    y = list(y)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.batch(bs)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(bs).cache()\n",
    "\n",
    "train_ds = make_dataset(x_train, y_train,BS)\n",
    "val_ds = make_dataset(x_val, y_val,BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        init_lr=0.00001,\n",
    "        lr_after_warmup=0.001,\n",
    "        final_lr=0.00001,\n",
    "        warmup_epochs=15,\n",
    "        decay_epochs=85,\n",
    "        steps_per_epoch=203,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.init_lr = init_lr\n",
    "        self.lr_after_warmup = lr_after_warmup\n",
    "        self.final_lr = final_lr\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.decay_epochs = decay_epochs\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "    def calculate_lr(self, epoch):\n",
    "        \"\"\" linear warm up - linear decay \"\"\"\n",
    "        warmup_lr = (\n",
    "            self.init_lr\n",
    "            + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n",
    "        )\n",
    "        decay_lr = tf.math.maximum(\n",
    "            self.final_lr,\n",
    "            self.lr_after_warmup\n",
    "            - (epoch - self.warmup_epochs)\n",
    "            * (self.lr_after_warmup - self.final_lr)\n",
    "            / (self.decay_epochs),\n",
    "        )\n",
    "        return tf.math.minimum(warmup_lr, decay_lr)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        epoch = step // self.steps_per_epoch\n",
    "        return self.calculate_lr(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "        #\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim, input_length = SEQ_LEN)\n",
    "        \n",
    "        # token embedding of features will be merged so shape pf position embedding output dim must match \n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim*FEATS)\n",
    "        \n",
    "        \n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        \n",
    "        # merging feature and embedding dimentions.\n",
    "        emb_shape = tf.shape(embedded_tokens) # (bs, seqlen, feats, embdim)\n",
    "        embedded_tokens = tf.reshape(embedded_tokens, [emb_shape[0], emb_shape[1],emb_shape[-2]*emb_shape[-1]])\n",
    "        #print(f\"shape of token emb reshaped: {embedded_tokens}\" ) # (bs, seqlen, feats*embdim)\n",
    "\n",
    "        length = tf.shape(embedded_tokens)[-2]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        \n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "\n",
    "        \n",
    "        ret = embedded_tokens + embedded_positions\n",
    "        return ret\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            # Ignoring this as all my sequences are of the same length\n",
    "            print(f\"encoder mask is not none: {mask}- but will be set to none\")\n",
    "            padding_mask = None\n",
    "            \n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        \n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            # Ignoring this as all my sequences are of the same length\n",
    "            print(f\"mask is not None: {mask}\\n but will be set to None\")\n",
    "            padding_mask = None\n",
    "        \n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        \n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "        \n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        \n",
    "        \n",
    "        ret = self.layernorm_3(out_2 + proj_output)\n",
    "        \n",
    "        # dealing with merged feat+emb dim\n",
    "        ret_shape = tf.shape(ret)\n",
    "        ret = tf.reshape(ret, (ret_shape[0], ret_shape[1], 60, embed_dim))\n",
    "        print(f\"decoder ret reshaped  = {ret}\")\n",
    "        \n",
    "        return ret\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirrored_strategy.scope():\n",
    "    encoder_inputs = keras.Input(shape=(SEQ_LEN,FEATS,)\n",
    "                                 , dtype=\"int64\", name=\"encoder_inputs\")\n",
    "    x = PositionalEmbedding(SEQ_LEN, vocab_size, embed_dim)(encoder_inputs)\n",
    "    print(x.shape)\n",
    "    encoder_outputs = TransformerEncoder(embed_dim*FEATS, latent_dim, num_heads)(x)\n",
    "    encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "    decoder_inputs = keras.Input(shape=(SEQ_LEN,FEATS,)\n",
    "                                 , dtype=\"int64\", name=\"decoder_inputs\")\n",
    "    encoded_seq_inputs = keras.Input(shape=(None, embed_dim*FEATS,), name=\"decoder_state_inputs\")\n",
    "    x = PositionalEmbedding(SEQ_LEN, vocab_size, embed_dim)(decoder_inputs)\n",
    "    x = TransformerDecoder(embed_dim*FEATS, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x) \n",
    "    decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "    transformer = keras.Model(\n",
    "        [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = CustomSchedule(\n",
    "    init_lr=0.0001,\n",
    "    lr_after_warmup=0.001,\n",
    "    final_lr=0.0001,\n",
    "    warmup_epochs=15,\n",
    "    decay_epochs=85,\n",
    "    steps_per_epoch= x_train.shape[0]/BS,\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5, verbose=1)\n",
    "checkpoint_filepath = '../data/models/checkpoint-transformer_translator.h5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True, verbose=1)\n",
    "\n",
    "\n",
    "transformer.summary()\n",
    "transformer.compile(\n",
    "    optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "history = transformer.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=[early_stopping, checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload saved model\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(SEQ_LEN,FEATS,)\n",
    "                                 , dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(SEQ_LEN, vocab_size, embed_dim)(encoder_inputs)\n",
    "\n",
    "encoder_outputs = TransformerEncoder(embed_dim*FEATS, latent_dim, num_heads)(x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(SEQ_LEN,FEATS,)\n",
    "                                 , dtype=\"int64\", name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim*FEATS,), name=\"decoder_state_inputs\")\n",
    "x = PositionalEmbedding(SEQ_LEN, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim*FEATS, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x) \n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "transformer_reload = keras.Model(\n",
    "        [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "transformer_reload.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = x_train[0:1,:]\n",
    "targ = y_train[0:1,:]\n",
    "print(inp.shape)\n",
    "print(inp)\n",
    "print(targ.shape)\n",
    "\n",
    "\n",
    "pred = transformer_reload([inp, targ])\n",
    "print(f\"prediction shape: {pred.shape}\")\n",
    "predicted = np.argmax(pred, axis=-1)\n",
    "print(predicted.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ex_to_tsv(ex, fn):\n",
    "    num_frames = ex.shape[0]\n",
    "    \n",
    "    \n",
    "    freq = 30\n",
    "    marker_names = ['MARKER_NAMES','Head','neck','rsho','relb','rwri','rhan','lsho','lelb','lwri','lhan','back','root','rhip','lhip','rknee','lknee','rank','lank', 'rfoot', 'lfoot']\n",
    "    \n",
    "    with open('../animations/tsv/'+fn+'.tsv', 'wt') as out_file:\n",
    "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "        tsv_writer.writerow(['NO_OF_FRAMES', num_frames])\n",
    "        tsv_writer.writerow(['NO_OF_CAMERAS', 0])\n",
    "        tsv_writer.writerow(['NO_OF_MARKERS', 20])\n",
    "        tsv_writer.writerow(['FREQUENCY', freq])\n",
    "        tsv_writer.writerow(['NO_OF_ANALOG', 0])\n",
    "        tsv_writer.writerow(['ANALOG_FREQUENCY', 0])\n",
    "        tsv_writer.writerow(['DESCRIPTION--', ''])\n",
    "        tsv_writer.writerow(['TIME_STAMP--', ''])\n",
    "        tsv_writer.writerow(['DATA_INCLUDED', '3D'])\n",
    "        tsv_writer.writerow(marker_names)\n",
    "\n",
    "        \n",
    "        for frame in range(num_frames):\n",
    "            tsv_writer.writerow(ex[frame,:])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ex_to_tsv(predicted[0], 'PRED')\n",
    "write_ex_to_tsv(inp[0], 'INPUT')\n",
    "write_ex_to_tsv(targ[0], 'TARGET')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
